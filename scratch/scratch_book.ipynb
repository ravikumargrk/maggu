{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f23a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import nltk\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471584b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory and make sure it's in the path BEFORE downloading\n",
    "os.makedirs(\"./nltk_data\", exist_ok=True)\n",
    "nltk.data.path.insert(0, \"./nltk_data\")  # Add to the beginning of the search path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8316954c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download successful: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to ./nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download punkt and verify success\n",
    "download_result = nltk.download('punkt', download_dir=\"./nltk_data\")\n",
    "print(f\"Download successful: {download_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bd9a23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK data path: ['./nltk_data', './nltk_data', '/home/codespace/nltk_data', '/usr/local/python/3.12.1/nltk_data', '/usr/local/python/3.12.1/share/nltk_data', '/usr/local/python/3.12.1/lib/nltk_data', '/usr/share/nltk_data', '/usr/local/share/nltk_data', '/usr/lib/nltk_data', '/usr/local/lib/nltk_data', './nltk_data', './nltk_data']\n",
      "Available tokenizers: ['punkt.zip', 'punkt']\n"
     ]
    }
   ],
   "source": [
    "# List available data to verify punkt is there\n",
    "print(f\"NLTK data path: {nltk.data.path}\")\n",
    "try:\n",
    "    print(f\"Available tokenizers: {os.listdir('./nltk_data/tokenizers')}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error checking tokenizers: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf111cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization error: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - './nltk_data'\n",
      "    - './nltk_data'\n",
      "    - '/home/codespace/nltk_data'\n",
      "    - '/usr/local/python/3.12.1/nltk_data'\n",
      "    - '/usr/local/python/3.12.1/share/nltk_data'\n",
      "    - '/usr/local/python/3.12.1/lib/nltk_data'\n",
      "    - '/usr/share/nltk_data'\n",
      "    - '/usr/local/share/nltk_data'\n",
      "    - '/usr/lib/nltk_data'\n",
      "    - '/usr/local/lib/nltk_data'\n",
      "    - './nltk_data'\n",
      "    - './nltk_data'\n",
      "**********************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try a simple tokenization to verify it works\n",
    "try:\n",
    "    test_tokens = word_tokenize(\"This is a test.\")\n",
    "    print(f\"Test tokenization: {test_tokens}\")\n",
    "except Exception as e:\n",
    "    print(f\"Tokenization error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77efe3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now continue with your code\n",
    "corpus = [\n",
    "    \"best view comes after the hardest climb\",\n",
    "    \"it always seems impossible until it's done\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4779a9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bow_representation(corpus, frequency=True):\n",
    "    # Simplify vocabulary creation to avoid potential issues\n",
    "    vocabulary = set()\n",
    "    for sentence in corpus:\n",
    "        words = sentence.lower().split()\n",
    "        vocabulary.update(words)\n",
    "    \n",
    "    print(f\"Vocabulary: {vocabulary}\")\n",
    "    \n",
    "    bow_rep = []\n",
    "    for sentence in corpus:\n",
    "        sentence_rep = {v: 0 for v in vocabulary}\n",
    "        # Use simple split as a fallback if tokenization fails\n",
    "        try:\n",
    "            words = word_tokenize(sentence.lower())\n",
    "            print(f\"Tokenized: {words}\")\n",
    "        except:\n",
    "            words = sentence.lower().split()\n",
    "            print(f\"Fallback split: {words}\")\n",
    "            \n",
    "        for word in words:\n",
    "            if word in vocabulary:\n",
    "                if frequency:\n",
    "                    sentence_rep[word] += 1\n",
    "                else:\n",
    "                    sentence_rep[word] = 1\n",
    "        bow_rep.append(sentence_rep)\n",
    "    return bow_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb8f7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'climb', 'hardest', 'until', 'impossible', 'best', \"it's\", 'done', 'view', 'always', 'after', 'it', 'the', 'seems', 'comes'}\n",
      "Fallback split: ['best', 'view', 'comes', 'after', 'the', 'hardest', 'climb']\n",
      "Fallback split: ['it', 'always', 'seems', 'impossible', 'until', \"it's\", 'done']\n",
      "                                            climb  hardest  until  impossible  \\\n",
      "best view comes after the hardest climb         1        1      0           0   \n",
      "it always seems impossible until it's done      0        0      1           1   \n",
      "\n",
      "                                            best  it's  done  view  always  \\\n",
      "best view comes after the hardest climb        1     0     0     1       0   \n",
      "it always seems impossible until it's done     0     1     1     0       1   \n",
      "\n",
      "                                            after  it  the  seems  comes  \n",
      "best view comes after the hardest climb         1   0    1      0      1  \n",
      "it always seems impossible until it's done      0   1    0      1      0  \n"
     ]
    }
   ],
   "source": [
    "# Try your function\n",
    "bow_representation = get_bow_representation(corpus, True)\n",
    "df = pd.DataFrame(bow_representation)\n",
    "df.index = corpus\n",
    "print(df)  # Use print instead of display for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c88af6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
